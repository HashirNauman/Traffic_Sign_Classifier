{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HashirNauman/Traffic_Sign_Classifier/blob/main/Traffic_Sign_Classifier_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Znw6lZYOQaAg",
        "outputId": "d2e886ac-3060-4d08-f025-94e59b661ed2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset path: /kaggle/input/gtsrb-german-traffic-sign\n",
            "GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
            "--- Stage A: Training head only ---\n",
            "Epoch 1/10\n",
            "\u001b[1m1960/1960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 315ms/step - accuracy: 0.0764 - loss: 3.6117 - val_accuracy: 0.2042 - val_loss: 3.1383\n",
            "Epoch 2/10\n",
            "\u001b[1m1960/1960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 269ms/step - accuracy: 0.1719 - loss: 3.1535 - val_accuracy: 0.2619 - val_loss: 2.8912\n",
            "Epoch 3/10\n",
            "\u001b[1m1960/1960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 257ms/step - accuracy: 0.2127 - loss: 2.9330 - val_accuracy: 0.3107 - val_loss: 2.6642\n",
            "Epoch 4/10\n",
            "\u001b[1m1960/1960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 256ms/step - accuracy: 0.2529 - loss: 2.7489 - val_accuracy: 0.3233 - val_loss: 2.5228\n",
            "Epoch 5/10\n",
            "\u001b[1m1960/1960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m493s\u001b[0m 252ms/step - accuracy: 0.2707 - loss: 2.6352 - val_accuracy: 0.3386 - val_loss: 2.4532\n",
            "Epoch 6/10\n",
            "\u001b[1m1960/1960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 256ms/step - accuracy: 0.2977 - loss: 2.5145 - val_accuracy: 0.3537 - val_loss: 2.3261\n",
            "Epoch 7/10\n",
            "\u001b[1m1960/1960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 256ms/step - accuracy: 0.3144 - loss: 2.4333 - val_accuracy: 0.3798 - val_loss: 2.2408\n",
            "Epoch 8/10\n",
            "\u001b[1m1960/1960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 237ms/step - accuracy: 0.3263 - loss: 2.3785 - val_accuracy: 0.4048 - val_loss: 2.1534\n",
            "Epoch 9/10\n",
            "\u001b[1m1960/1960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 236ms/step - accuracy: 0.3446 - loss: 2.2952 - val_accuracy: 0.4013 - val_loss: 2.1427\n",
            "Epoch 10/10\n",
            "\u001b[1m1960/1960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 233ms/step - accuracy: 0.3409 - loss: 2.2856 - val_accuracy: 0.4037 - val_loss: 2.0895\n",
            "--- Stage B: Fine-tuning last conv block ---\n",
            "Epoch 1/10\n",
            "\u001b[1m1960/1960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 256ms/step - accuracy: 0.4603 - loss: 1.8042 - val_accuracy: 0.6832 - val_loss: 1.0798\n",
            "Epoch 2/10\n",
            "\u001b[1m1960/1960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 256ms/step - accuracy: 0.6213 - loss: 1.2306 - val_accuracy: 0.7545 - val_loss: 0.8169\n",
            "Epoch 3/10\n",
            "\u001b[1m1960/1960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 256ms/step - accuracy: 0.6940 - loss: 0.9844 - val_accuracy: 0.8126 - val_loss: 0.6589\n",
            "Epoch 4/10\n",
            "\u001b[1m1960/1960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 256ms/step - accuracy: 0.7428 - loss: 0.8259 - val_accuracy: 0.8452 - val_loss: 0.5257\n",
            "Epoch 5/10\n",
            "\u001b[1m1960/1960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 256ms/step - accuracy: 0.7823 - loss: 0.7007 - val_accuracy: 0.8742 - val_loss: 0.4498\n",
            "Epoch 6/10\n",
            "\u001b[1m1960/1960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 256ms/step - accuracy: 0.8119 - loss: 0.6107 - val_accuracy: 0.8835 - val_loss: 0.3909\n",
            "Epoch 7/10\n",
            "\u001b[1m1960/1960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 256ms/step - accuracy: 0.8302 - loss: 0.5525 - val_accuracy: 0.9143 - val_loss: 0.3191\n",
            "Epoch 8/10\n",
            "\u001b[1m1960/1960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 245ms/step - accuracy: 0.8492 - loss: 0.4832 - val_accuracy: 0.9297 - val_loss: 0.2806\n",
            "Epoch 9/10\n",
            "\u001b[1m1960/1960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m480s\u001b[0m 245ms/step - accuracy: 0.8693 - loss: 0.4248 - val_accuracy: 0.9295 - val_loss: 0.2429\n",
            "Epoch 10/10\n",
            "\u001b[1m1960/1960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 256ms/step - accuracy: 0.8815 - loss: 0.3892 - val_accuracy: 0.9343 - val_loss: 0.2206\n",
            "Evaluating on validation set...\n",
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 101ms/step - accuracy: 0.9391 - loss: 0.2181\n",
            "Val Loss: 0.2258, Val Accuracy: 0.9339\n",
            "Model saved as gtsrb_finetuned_model.keras\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import kagglehub\n",
        "\n",
        "# Download latest dataset version\n",
        "path = kagglehub.dataset_download(\"meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\")\n",
        "print(\"Dataset path:\", path)\n",
        "\n",
        "# Constants\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 16\n",
        "NUM_CLASSES = 43\n",
        "EPOCHS = 10\n",
        "\n",
        "# Helper: crop to ROI then resize\n",
        "def preprocess_image(row, base_dir, target_size):\n",
        "    img_path = os.path.join(base_dir, row.Path)\n",
        "    img = cv2.imread(img_path)\n",
        "    # Extract ROI coords\n",
        "    x1, y1, x2, y2 = map(int, [row[\"Roi.X1\"], row[\"Roi.Y1\"], row[\"Roi.X2\"], row[\"Roi.Y2\"]])\n",
        "    crop = img[y1:y2, x1:x2]\n",
        "    resized = cv2.resize(crop, target_size)\n",
        "    return resized\n",
        "\n",
        "# Generator yielding batches of (images, labels)\n",
        "def make_dataset(df, base_dir, batch_size, subset, datagen):\n",
        "    df = df.copy().reset_index(drop=True)\n",
        "    num_samples = len(df)\n",
        "    while True:\n",
        "        idxs = np.random.choice(num_samples, batch_size)\n",
        "        images, labels = [], []\n",
        "        for i in idxs:\n",
        "            row = df.loc[i]\n",
        "            img = preprocess_image(row, base_dir, IMAGE_SIZE)\n",
        "            if subset == \"training\":\n",
        "                img = datagen.random_transform(img)\n",
        "            img = img.astype(\"float32\") / 255.0\n",
        "            images.append(img)\n",
        "            labels.append(int(row.ClassId))\n",
        "        X = np.stack(images)\n",
        "        y = tf.keras.utils.to_categorical(labels, NUM_CLASSES)\n",
        "        yield X, y\n",
        "\n",
        "# Load and split data\n",
        "df = pd.read_csv(os.path.join(path, \"Train.csv\"))\n",
        "df.ClassId = df.ClassId.astype(int)\n",
        "train_df = df.sample(frac=0.8, random_state=42)\n",
        "val_df   = df.drop(train_df.index)\n",
        "\n",
        "# DataGenerators for augmentation and normalization\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ")\n",
        "val_datagen = ImageDataGenerator()\n",
        "\n",
        "steps_per_epoch = len(train_df) // BATCH_SIZE\n",
        "validation_steps = len(val_df)   // BATCH_SIZE\n",
        "train_gen = make_dataset(train_df, path, BATCH_SIZE, \"training\", train_datagen)\n",
        "val_gen   = make_dataset(val_df,   path, BATCH_SIZE, \"validation\", val_datagen)\n",
        "\n",
        "# Build model (Stage A: head only)\n",
        "def build_model():\n",
        "    base = VGG16(weights=\"imagenet\", include_top=False,\n",
        "                 input_shape=(*IMAGE_SIZE, 3))\n",
        "    base.trainable = False\n",
        "\n",
        "    x = base.output\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(128, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
        "\n",
        "    model = models.Model(inputs=base.input, outputs=outputs)\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(1e-4),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Main training routine\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
        "    model = build_model()\n",
        "    early_stop = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
        "\n",
        "    # Stage A: train head\n",
        "    print(\"--- Stage A: Training head only ---\")\n",
        "    model.fit(\n",
        "        train_gen,\n",
        "        validation_data=val_gen,\n",
        "        epochs=EPOCHS,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        validation_steps=validation_steps,\n",
        "        callbacks=[early_stop]\n",
        "    )\n",
        "\n",
        "    # Stage B: fine-tune last conv block\n",
        "    for layer in model.layers:\n",
        "        if layer.name.startswith(\"block5_\"):\n",
        "            layer.trainable = True\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(1e-5),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    print(\"--- Stage B: Fine-tuning last conv block ---\")\n",
        "    model.fit(\n",
        "        train_gen,\n",
        "        validation_data=val_gen,\n",
        "        epochs=EPOCHS,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        validation_steps=validation_steps,\n",
        "        callbacks=[early_stop]\n",
        "    )\n",
        "\n",
        "    # Final evaluation & saving\n",
        "    print(\"Evaluating on validation set...\")\n",
        "    loss, acc = model.evaluate(val_gen, steps=validation_steps)\n",
        "    print(f\"Val Loss: {loss:.4f}, Val Accuracy: {acc:.4f}\")\n",
        "    model.save(\"gtsrb_finetuned_model.keras\")\n",
        "    print(\"Model saved as gtsrb_finetuned_model.keras\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNwZWLadMpCJDIMjk7ohEK0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}